{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jbridg12/Alzheimer_GAN/blob/main/AlzheimersGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initial Setup"
      ],
      "metadata": {
        "id": "bdfvkmcbLHwd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KPtoZeFdJ3-E"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "tf.config.run_functions_eagerly(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "146E1GX6RrbI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Lem5oV-HSxel"
      },
      "outputs": [],
      "source": [
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/MyDrive/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5uFqMZsfS2H3"
      },
      "outputs": [],
      "source": [
        "%cd /content/gdrive/MyDrive/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Processing"
      ],
      "metadata": {
        "id": "9EA1GiBbJFxD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rAacXn8pS-Hz"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d sachinkumar413/alzheimer-mri-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "pDvme1tmT40L"
      },
      "outputs": [],
      "source": [
        "from zipfile import ZipFile\n",
        "with ZipFile('alzheimer-mri-dataset.zip', 'r') as zipper:\n",
        "  zipper.extractall()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from os import listdir\n",
        "from os.path import join, isdir\n",
        "class_name = np.array([f for f in listdir('./Dataset') if isdir(join('./Dataset', f))])\n",
        "n_classes = len(class_name)\n",
        "print(n_classes)"
      ],
      "metadata": {
        "id": "KyxKkrSYN8KJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# From https://opensource.com/article/17/2/python-tricks-artists\n",
        "from os import listdir\n",
        "from PIL import Image\n",
        "\n",
        "bad_files = []\n",
        "for dir in listdir('Dataset/'):\n",
        "  for file in listdir('Dataset/'+dir):\n",
        "    # print(file)\n",
        "    # break\n",
        "    if file.endswith('.jpg'):\n",
        "      try:\n",
        "        img = Image.open('Dataset/'+dir+'/'+file)\n",
        "        img.verify()\n",
        "      except (IOError, SyntaxError) as e:\n",
        "        print('Bad file:', file)\n",
        "        path = 'Dataset/'+dir+'/'+file\n",
        "        bad_files.append(path)"
      ],
      "metadata": {
        "id": "FcdILfLfnb6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(bad_files))\n",
        "for file in bad_files:\n",
        "  os.remove(file)"
      ],
      "metadata": {
        "id": "MpA7eTEGpohb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8pGVNPRXDsb"
      },
      "outputs": [],
      "source": [
        "# For replicable results\n",
        "SEED = 0\n",
        "# Size of Latent Input\n",
        "noise_dim = 100\n",
        "num_examples_to_generate = 16\n",
        "# Size of the images is (128,128)\n",
        "IMAGE_SIZE = (128, 128)\n",
        "# Default batch size\n",
        "BATCH_SIZE = 32\n",
        "# Images are grayscale\n",
        "COLOR_MODE = \"grayscale\"\n",
        "\n",
        "# data_dir = \"Dataset/\"\n",
        "data_dir=os.path.join('train_test/', 'train')\n",
        "\n",
        "tf.random.set_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "train_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    'Dataset/',\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=SEED,\n",
        "    color_mode=COLOR_MODE,\n",
        "    image_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process(image,label):\n",
        "    image = tf.cast(((tf.cast(image, tf.float32)/127.5) -1)  ,tf.float32)\n",
        "    return image,label\n",
        "\n",
        "train_data = train_data.map(process)"
      ],
      "metadata": {
        "id": "aB0_YlV8JT6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, l in train_data:\n",
        "  print(i.shape)\n",
        "  break"
      ],
      "metadata": {
        "id": "OKbaNjnzDtNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Examples"
      ],
      "metadata": {
        "id": "OYNpu6O9Jtgm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_data.take(1):\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(tf.image.grayscale_to_rgb(images[i]).numpy().astype(\"uint8\"))\n"
      ],
      "metadata": {
        "id": "fGVUN-7dWrde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Model Architectures"
      ],
      "metadata": {
        "id": "D9URMywhLAyR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generator_model():\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(layers.Dense(8*8*256, use_bias=False, input_shape=(noise_dim+1,)))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "\n",
        "  model.add(layers.Reshape((8, 8, 256)))\n",
        "  assert model.output_shape == (None, 8, 8, 256)\n",
        "\n",
        "  model.add(layers.Conv2DTranspose(128, (3, 3), strides=(1, 1), padding='same', use_bias=False))\n",
        "  assert model.output_shape == (None, 8, 8, 128)\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "\n",
        "  model.add(layers.Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same', use_bias=False))\n",
        "  assert model.output_shape == (None, 16, 16, 128)\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "\n",
        "  model.add(layers.Conv2DTranspose(64, (3, 3), strides=(1, 1), padding='same', use_bias=False))\n",
        "  assert model.output_shape == (None, 16, 16, 64)\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "\n",
        "  model.add(layers.Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same', use_bias=False))\n",
        "  assert model.output_shape == (None, 32, 32, 64)\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "\n",
        "  model.add(layers.Conv2DTranspose(32, (3, 3), strides=(1, 1), padding='same', use_bias=False))\n",
        "  assert model.output_shape == (None, 32, 32, 32)\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "\n",
        "  model.add(layers.Conv2DTranspose(32, (3, 3), strides=(2, 2), padding='same', use_bias=False))\n",
        "  assert model.output_shape == (None, 64, 64, 32)\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "\n",
        "  model.add(layers.Conv2DTranspose(16, (3, 3), strides=(1, 1), padding='same', use_bias=False))\n",
        "  assert model.output_shape == (None, 64, 64, 16)\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "\n",
        "  model.add(layers.Conv2DTranspose(16, (3, 3), strides=(2, 2), padding='same', use_bias=False))\n",
        "  assert model.output_shape == (None, 128, 128, 16)\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "\n",
        "\n",
        "  model.add(layers.Conv2DTranspose(1, (3, 3), strides=(1, 1), padding='same', use_bias=False, activation='tanh'))\n",
        "  assert model.output_shape == (None, 128, 128, 1)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "5aR1UZuybf9U"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def discriminator_model():\n",
        "  logitmodel = tf.keras.Sequential()\n",
        "\n",
        "  logitmodel.add(layers.Conv2D(64,3,2,'same', input_shape=(128,128,1)))\n",
        "  logitmodel.add(layers.LeakyReLU())\n",
        "  logitmodel.add(layers.Dropout(0.3))\n",
        "\n",
        "  logitmodel.add(layers.Conv2D(128,3,2,'same'))\n",
        "  logitmodel.add(layers.LeakyReLU())\n",
        "  logitmodel.add(layers.Dropout(0.3))\n",
        "\n",
        "  logitmodel.add(layers.Conv2D(64,3,2,'same'))\n",
        "  logitmodel.add(layers.LeakyReLU())\n",
        "  logitmodel.add(layers.Dropout(0.3))\n",
        "\n",
        "  logitmodel.add(layers.Conv2D(32,3,2,'same'))\n",
        "  logitmodel.add(layers.LeakyReLU())\n",
        "  logitmodel.add(layers.Dropout(0.3))\n",
        "\n",
        "  logitmodel.add(layers.Conv2D(8,3,2,'same'))\n",
        "  logitmodel.add(layers.LeakyReLU())\n",
        "  logitmodel.add(layers.Dropout(0.3))\n",
        "\n",
        "  logitmodel.add(layers.Flatten())\n",
        "  logitmodel.add(layers.Activation('sigmoid'))\n",
        "  logitmodel.add(layers.Dense(1))\n",
        "  \n",
        "  return logitmodel"
      ],
      "metadata": {
        "id": "OxWvaGiyebDq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = generator_model()\n",
        "discriminator = discriminator_model()"
      ],
      "metadata": {
        "id": "GDQWDjnwkDA4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(generator, show_shapes=True, dpi=64)"
      ],
      "metadata": {
        "id": "kD8D80deKovf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(discriminator, show_shapes=True, dpi=64)"
      ],
      "metadata": {
        "id": "kSAVlDFeLP0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Loss and Optimizers"
      ],
      "metadata": {
        "id": "u9ZDVLfRK9lk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ent_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ],
      "metadata": {
        "id": "u8kWNoTfggLc"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = ent_loss(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = ent_loss(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss"
      ],
      "metadata": {
        "id": "RVnGN9JUfqbc"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generator_loss(fake_output):\n",
        "    return ent_loss(tf.ones_like(fake_output), fake_output)"
      ],
      "metadata": {
        "id": "YXeeqZzqgQx1"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen_lr = 0.0001\n",
        "dis_lr = 0.0001\n",
        "\n",
        "generator_optimizer = tf.keras.optimizers.Adam(gen_lr)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(dis_lr)"
      ],
      "metadata": {
        "id": "53r2FABOjkop"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "9mZIgh_tK2YN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "@tf.function\n",
        "def train_step(image, label):\n",
        "\n",
        "    # Add label to noise and images\n",
        "    noise = tf.random.normal((label.shape[0], noise_dim)).numpy()\n",
        "    l = label.numpy()\n",
        "    noises = []\n",
        "    for i in range(l.shape[0]):\n",
        "      noises.append(np.append(noise[i], l[i]))\n",
        "    \n",
        "    n_and_l = tf.convert_to_tensor(np.array(noises))\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "\n",
        "      generated_images = generator(n_and_l, training=True)\n",
        "\n",
        "      real_output = discriminator(image, training=True)\n",
        "      fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "      gen_loss = generator_loss(fake_output)\n",
        "      disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
      ],
      "metadata": {
        "id": "JP4sPbdXj_G-"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "def train(dataset, epochs):\n",
        "  for (step, input_image) in train_data.repeat().take(EPOCHS).enumerate():\n",
        "    start = time.time()\n",
        "\n",
        "    train_step(input_image[0], input_image[1])      \n",
        "\n",
        "    print ('Time for epoch {} is {} sec'.format(step + 1, time.time()-start))\n"
      ],
      "metadata": {
        "id": "twMbwdQXkbqo"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 7000\n",
        "train(train_data, EPOCHS)"
      ],
      "metadata": {
        "id": "iYjC1gQ9nzfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_labels = np.arange(0, n_classes).reshape(-1, 1)\n",
        "print(num_labels.shape)"
      ],
      "metadata": {
        "id": "ELBuIPtcQP8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example"
      ],
      "metadata": {
        "id": "b-NKwmh7LNEb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_label = 3\n",
        "\n",
        "test_noise = tf.random.normal([1, noise_dim]).numpy()\n",
        "tst_in = []\n",
        "tst_in.append(np.append(test_noise[0], target_label))\n",
        "test_input = tf.convert_to_tensor(np.array(tst_in))\n",
        "gen_img = generator(test_input, training=False)\n",
        "plt.imshow(gen_img[0,:,:,0], cmap='gray')"
      ],
      "metadata": {
        "id": "DtTDDok8zs90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save Model"
      ],
      "metadata": {
        "id": "5qbSYg_uLPQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator.save('saved_model/gen1')"
      ],
      "metadata": {
        "id": "oEoWUQcmNLsP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "name": "AlzheimersGAN.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}